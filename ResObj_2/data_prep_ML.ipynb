{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b14aaf0e-cfcf-4091-9f6e-2d0a4eb6fa8c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "import requests\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae8d4c1-807f-4c64-9ed2-a15b70851dd3",
   "metadata": {},
   "source": [
    "# Data preparation for Research Objective 2\n",
    "Requires:\n",
    "\n",
    "- df_all_ctls_identified_v2.pkl (created with \"Identification_results.ipynb\")\n",
    "- dict_all_cells_v2.pkl (created with \"Identify_CID_v2.ipynb\")\n",
    "\n",
    "Outputs a dataframe for the ML tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e42b8589-427e-4ebf-8d9b-fd5cd74ae89a",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'data_RO2/dict_all_cells_v2.pkl'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Execute to make sure that you have the newest version of the RO1 results.\n",
    "# WARNING: This overwrites the files if they already exist.\n",
    "shutil.copyfile(\"../ResObj_1/data_RO1/df_all_ctls_identified_v2.pkl\", \"data_RO2/df_all_ctls_identified_v2.pkl\")\n",
    "shutil.copyfile(\"../ResObj_1/data_RO1/dict_all_cells_v2.pkl\", \"data_RO2/dict_all_cells_v2.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731ff36-e3df-4cec-acdd-f6dbcf713129",
   "metadata": {},
   "source": [
    "# Download from NOMAD API\n",
    "Data are downloaded again for Research Objective 2 because additional properties are needed, e.g. PCE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdadcd20-720e-4587-b019-2f8953b249d1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 1/43\n",
      "Progress: 2/43\n",
      "Progress: 3/43\n",
      "Progress: 4/43\n",
      "Progress: 5/43\n",
      "Progress: 6/43\n",
      "Progress: 7/43\n",
      "Progress: 8/43\n",
      "Progress: 9/43\n",
      "Progress: 10/43\n",
      "Progress: 11/43\n",
      "Progress: 12/43\n",
      "Progress: 13/43\n",
      "Progress: 14/43\n",
      "Progress: 15/43\n",
      "Progress: 16/43\n",
      "Progress: 17/43\n",
      "Progress: 18/43\n",
      "Progress: 19/43\n",
      "Progress: 20/43\n",
      "Progress: 21/43\n",
      "Progress: 22/43\n",
      "Progress: 23/43\n",
      "Progress: 24/43\n",
      "Progress: 25/43\n",
      "Progress: 26/43\n",
      "Progress: 27/43\n",
      "Progress: 28/43\n",
      "Progress: 29/43\n",
      "Progress: 30/43\n",
      "Progress: 31/43\n",
      "Progress: 32/43\n",
      "Progress: 33/43\n",
      "Progress: 34/43\n",
      "Progress: 35/43\n",
      "Progress: 36/43\n",
      "Progress: 37/43\n",
      "Progress: 38/43\n",
      "Progress: 39/43\n",
      "Progress: 40/43\n",
      "Progress: 41/43\n",
      "Progress: 42/43\n",
      "Progress: 43/43\n",
      "Progress: 44/43\n"
     ]
    }
   ],
   "source": [
    "base_url = 'https://nomad-lab.eu/prod/v1/api/v1/'\n",
    "\n",
    "def extract_values(entry):\n",
    "    try:\n",
    "        bandgaps.append(entry['results']['properties']['electronic']['band_structure_electronic'][0]['band_gap'][0]['value'])\n",
    "    except:\n",
    "        bandgaps.append('None')\n",
    "    try:\n",
    "        reduced_formulas.append(entry['results']['material']['chemical_formula_reduced'])\n",
    "    except:\n",
    "        reduced_formulas.append('None')\n",
    "    try:\n",
    "        pce.append(entry['results']['properties']['optoelectronic']['solar_cell']['efficiency'])\n",
    "    except:\n",
    "        pce.append('None')\n",
    "    try:\n",
    "        device_stack.append(entry['results']['properties']['optoelectronic']['solar_cell']['device_stack'])\n",
    "    except:\n",
    "        device_stack.append('None')\n",
    "    try:\n",
    "        htl.append(entry['results']['properties']['optoelectronic']['solar_cell']['hole_transport_layer'])\n",
    "    except:\n",
    "        htl.append('None')\n",
    "    try:\n",
    "        etl.append(entry['results']['properties']['optoelectronic']['solar_cell']['electron_transport_layer'])\n",
    "    except:\n",
    "        etl.append('None')\n",
    "    try:\n",
    "        da.append(entry['results']['properties']['optoelectronic']['solar_cell']['device_area'])\n",
    "    except:\n",
    "        da.append('None')\n",
    "    try:\n",
    "        ill_int.append(entry['results']['properties']['optoelectronic']['solar_cell']['illumination_intensity'])\n",
    "    except:\n",
    "        ill_int.append('None')\n",
    "    return bandgaps, reduced_formulas, pce, device_stack, htl, etl, da, ill_int\n",
    "\n",
    "bandgaps =[]\n",
    "pce = []\n",
    "reduced_formulas = []\n",
    "htl = []\n",
    "etl = []\n",
    "device_stack = []\n",
    "da = []\n",
    "ill_int = []\n",
    "\n",
    "page_after_value = None\n",
    "count = 0\n",
    "\n",
    "while True:\n",
    "    count = count + 1\n",
    "    print(f\"Progress: {count}/44\")\n",
    "    data = requests.post(f'{base_url}entries/query', json={\n",
    "        \"owner\": \"visible\",\n",
    "        \"aggregations\": {},\n",
    "        \"query\": {\n",
    "            \"and\": [\n",
    "                {\"sections:all\": [\"nomad.datamodel.results.SolarCell\"]},\n",
    "                ]},\n",
    "        \"required\": {\n",
    "            \"results\":{\n",
    "                \"material\": {\n",
    "                    \"chemical_formula_reduced\":\"*\",\n",
    "                    \"structural_type\":\"*\"},\n",
    "                \"properties\": {\n",
    "                   \"optoelectronic\":{\n",
    "                      \"band_gap\":\"*\",\n",
    "                      \"solar_cell\":{\n",
    "                          \"open_circuit_voltage\":\"*\",\n",
    "                          \"short_circuit_current_density\":\"*\",\n",
    "                          \"fill_factor\":\"*\",\n",
    "                          \"efficiency\":\"*\",\n",
    "                          }}},},\n",
    "        },\n",
    "        \"pagination\": {\"page_size\": 1000,\n",
    "                       \"page_after_value\": page_after_value}\n",
    "        }).json()\n",
    "\n",
    "\n",
    "    if not data['data']:\n",
    "        break\n",
    "    if 'next_page_after_value' not in data['pagination'].keys():\n",
    "    # make sure to grasp the entries of the last page before breaking\n",
    "        for entry in data['data']:\n",
    "            if 'results' not in entry.keys():\n",
    "                continue\n",
    "            else:\n",
    "                extract_values(entry)\n",
    "        break\n",
    "    page_after_value = data['pagination']['next_page_after_value']\n",
    "\n",
    "    for entry in data['data']:\n",
    "        if 'results' not in entry.keys():\n",
    "            continue\n",
    "        else:\n",
    "            extract_values(entry)\n",
    "            \n",
    "df = pd.DataFrame({\n",
    "    'reduced_formulas': reduced_formulas,\n",
    "    'bandgap': bandgaps,\n",
    "    'pce': pce,\n",
    "    'device_stack': device_stack,\n",
    "    'htl': htl,\n",
    "    'etl': etl,\n",
    "    'ill_int': ill_int,\n",
    "    'device_area': da,\n",
    "    })\n",
    "\n",
    "df.to_csv('data_RO2/df_pce_prediction.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c814b895-44a3-4a6d-a2af-950db280e6a2",
   "metadata": {},
   "source": [
    "# Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "64485b2a-fc78-438d-84da-edc860f6bf8c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw data length: 43108.\n",
      "Length of CTL identification info: 43108.\n",
      "After keeping only fully identified CTLs: 37713.\n",
      "After dropping NAs in device stack: 37713.\n",
      "After dropping None strings in reduced_formulas: 37160.\n",
      "After dropping NAs in reduced_formulas: 37160.\n",
      "After dropping cells that were measured at illumination intensity other than 1000 W/m^2: 36741.\n",
      "After dropping cells with device area greater than 25 mm^2: 34103.\n",
      "After dropping cells without pce information: 33382.\n",
      "After dropping cells with pce lower than 2: 31635.\n",
      "How many nones in bandgap: 7423\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reduced_formulas</th>\n",
       "      <th>etl</th>\n",
       "      <th>htl</th>\n",
       "      <th>bandgap</th>\n",
       "      <th>device_stack</th>\n",
       "      <th>pce</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ag20Bi20CsI60</td>\n",
       "      <td>[TiO2-c, TiO2-mp]</td>\n",
       "      <td>[P3HT]</td>\n",
       "      <td>1.86</td>\n",
       "      <td>['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ag20Bi20CsI60</td>\n",
       "      <td>[TiO2-c, TiO2-mp]</td>\n",
       "      <td>[PTB7-th]</td>\n",
       "      <td>1.86</td>\n",
       "      <td>['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...</td>\n",
       "      <td>3.530000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Ag2BiI5</td>\n",
       "      <td>[TiO2-c, TiO2-mp]</td>\n",
       "      <td>[PTAA]</td>\n",
       "      <td>2.22</td>\n",
       "      <td>['SLG', 'ITO', 'TiO2-c', 'TiO2-mp', 'Perovskit...</td>\n",
       "      <td>2.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Ag3BiI6</td>\n",
       "      <td>[TiO2-c, TiO2-mp]</td>\n",
       "      <td>[P3HT]</td>\n",
       "      <td>1.80</td>\n",
       "      <td>['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...</td>\n",
       "      <td>2.320000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Ag3BiI6</td>\n",
       "      <td>[TiO2-c, TiO2-mp]</td>\n",
       "      <td>[PTAA]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...</td>\n",
       "      <td>4.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5444</th>\n",
       "      <td>CsI3Sn</td>\n",
       "      <td>[TiO2-c]</td>\n",
       "      <td>[PTAA]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>['SLG', 'FTO', 'TiO2-c', 'Perovskite', 'PTAA',...</td>\n",
       "      <td>3.866667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5445</th>\n",
       "      <td>CsI3Sn</td>\n",
       "      <td>[TiO2-c, TiO2-mp]</td>\n",
       "      <td>[PTAA]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...</td>\n",
       "      <td>3.790000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5446</th>\n",
       "      <td>CsI3Sn</td>\n",
       "      <td>[TiO2-c, TiO2-mp]</td>\n",
       "      <td>[PTAA]</td>\n",
       "      <td>1.30</td>\n",
       "      <td>['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...</td>\n",
       "      <td>3.655000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5447</th>\n",
       "      <td>CsI3Sn</td>\n",
       "      <td>[TiO2-c, TiO2-mp]</td>\n",
       "      <td>[Spiro-MeOTAD]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...</td>\n",
       "      <td>2.230000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5448</th>\n",
       "      <td>CsI3Sn</td>\n",
       "      <td>[TiO2-c, TiO2-mp]</td>\n",
       "      <td>[m-MTDATA]</td>\n",
       "      <td>0.00</td>\n",
       "      <td>['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...</td>\n",
       "      <td>2.020000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5449 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     reduced_formulas                etl             htl  bandgap  \\\n",
       "0       Ag20Bi20CsI60  [TiO2-c, TiO2-mp]          [P3HT]     1.86   \n",
       "1       Ag20Bi20CsI60  [TiO2-c, TiO2-mp]       [PTB7-th]     1.86   \n",
       "2             Ag2BiI5  [TiO2-c, TiO2-mp]          [PTAA]     2.22   \n",
       "3             Ag3BiI6  [TiO2-c, TiO2-mp]          [P3HT]     1.80   \n",
       "4             Ag3BiI6  [TiO2-c, TiO2-mp]          [PTAA]     0.00   \n",
       "...               ...                ...             ...      ...   \n",
       "5444           CsI3Sn           [TiO2-c]          [PTAA]     0.00   \n",
       "5445           CsI3Sn  [TiO2-c, TiO2-mp]          [PTAA]     0.00   \n",
       "5446           CsI3Sn  [TiO2-c, TiO2-mp]          [PTAA]     1.30   \n",
       "5447           CsI3Sn  [TiO2-c, TiO2-mp]  [Spiro-MeOTAD]     0.00   \n",
       "5448           CsI3Sn  [TiO2-c, TiO2-mp]      [m-MTDATA]     0.00   \n",
       "\n",
       "                                           device_stack       pce  \n",
       "0     ['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...  3.530000  \n",
       "1     ['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...  3.530000  \n",
       "2     ['SLG', 'ITO', 'TiO2-c', 'TiO2-mp', 'Perovskit...  2.600000  \n",
       "3     ['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...  2.320000  \n",
       "4     ['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...  4.300000  \n",
       "...                                                 ...       ...  \n",
       "5444  ['SLG', 'FTO', 'TiO2-c', 'Perovskite', 'PTAA',...  3.866667  \n",
       "5445  ['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...  3.790000  \n",
       "5446  ['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...  3.655000  \n",
       "5447  ['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...  2.230000  \n",
       "5448  ['SLG', 'FTO', 'TiO2-c', 'TiO2-mp', 'Perovskit...  2.020000  \n",
       "\n",
       "[5449 rows x 6 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load data\n",
    "df = pd.read_csv('data_RO2/df_pce_prediction.csv')\n",
    "print(f\"Raw data length: {len(df)}.\")\n",
    "\n",
    "with open('data_RO2/df_all_ctls_identified_v2.pkl', 'rb') as f:\n",
    "    df_id = pickle.load(f)\n",
    "print(f\"Length of CTL identification info: {len(df_id)}.\")\n",
    "\n",
    "# Only keep fully identified cells\n",
    "df['both_identified'] = df_id['both_identified']\n",
    "df_all_identified = df[df['both_identified'] == True]\n",
    "print(f\"After keeping only fully identified CTLs: {len(df_all_identified)}.\")\n",
    "\n",
    "# drop cells without a device stack information\n",
    "df_all_identified['device_stack'].apply(ast.literal_eval)\n",
    "df_all_identified = df_all_identified.dropna(subset=['device_stack'])\n",
    "print(f\"After dropping NAs in device stack: {len(df_all_identified)}.\")\n",
    "\n",
    "# drop cells without reduced_formulas\n",
    "df_all_identified = df_all_identified[df_all_identified['reduced_formulas'] != \"None\"]\n",
    "print(f\"After dropping None strings in reduced_formulas: {len(df_all_identified)}.\")\n",
    "\n",
    "df_all_identified = df_all_identified.dropna(subset=['reduced_formulas'])\n",
    "print(f\"After dropping NAs in reduced_formulas: {len(df_all_identified)}.\")\n",
    "\n",
    "# eliminate cells that were measured at an illumination intensity other than 1000 W/m^2\n",
    "df_all_identified['ill_int'] = pd.to_numeric(df_all_identified['ill_int'], errors='coerce')\n",
    "df_all_identified = df_all_identified[df_all_identified['ill_int'] == 1000]\n",
    "print(f\"After dropping cells that were measured at illumination intensity other than 1000 W/m^2: {len(df_all_identified)}.\")\n",
    "\n",
    "# eliminate rows with large device areas\n",
    "df_all_identified['device_area'] = pd.to_numeric(df_all_identified['device_area'], errors='coerce')\n",
    "df_all_identified = df_all_identified[df_all_identified['device_area'] <= 0.000025]\n",
    "print(f\"After dropping cells with device area greater than 25 mm^2: {len(df_all_identified)}.\")\n",
    "\n",
    "\n",
    "# drop everything that is not further needed\n",
    "df_all_identified = df_all_identified.drop(columns=['both_identified', \n",
    "                                                    #'device_stack',\n",
    "                                                    'ill_int',\n",
    "                                                    'device_area',\n",
    "                                                   ])\n",
    "\n",
    "# transform etl and htl to lists\n",
    "df_all_identified['etl'] = df_all_identified['etl'].apply(ast.literal_eval)\n",
    "df_all_identified['htl'] = df_all_identified['htl'].apply(ast.literal_eval)\n",
    "\n",
    "\n",
    "# split entries separated with semicolons into proper comma separated lists\n",
    "for index, _ in df_all_identified.iterrows():\n",
    "    i = 0\n",
    "    while i < len(df_all_identified.at[index, \"etl\"]):\n",
    "        if \";\" in df_all_identified.at[index, \"etl\"][i]:\n",
    "            elements = df_all_identified.at[index, \"etl\"][i].split(\";\")\n",
    "            df_all_identified.at[index, \"etl\"] = df_all_identified.at[index, \"etl\"][:i] + elements + df_all_identified.at[index, \"etl\"][i+1:]\n",
    "        i += 1\n",
    "\n",
    "for index, _ in df_all_identified.iterrows():\n",
    "    i = 0\n",
    "    while i < len(df_all_identified.at[index, \"htl\"]):\n",
    "        if \";\" in df_all_identified.at[index, \"htl\"][i]:\n",
    "            elements = df_all_identified.at[index, \"htl\"][i].split(\";\")\n",
    "            df_all_identified.at[index, \"htl\"] = df_all_identified.at[index, \"htl\"][:i] + elements + df_all_identified.at[index, \"htl\"][i+1:]\n",
    "        i += 1\n",
    "        \n",
    "# transform pce to numeric\n",
    "df_all_identified['pce'] = pd.to_numeric(df_all_identified['pce'], errors='coerce')\n",
    "df_all_identified = df_all_identified.dropna(subset=['pce'])\n",
    "print(f\"After dropping cells without pce information: {len(df_all_identified)}.\")\n",
    "\n",
    "# drop cells with very low PCE\n",
    "df_all_identified = df_all_identified[df_all_identified['pce'] > 2]\n",
    "print(f\"After dropping cells with pce lower than 2: {len(df_all_identified)}.\")\n",
    "\n",
    "# transform bandgaps to proper size values, transforming nones into zeros\n",
    "df_all_identified['bandgap'] = pd.to_numeric(df_all_identified['bandgap'], errors='coerce')\n",
    "\n",
    "# check how many bandgaps are none\n",
    "df_check = df_all_identified.dropna(subset=['bandgap'])\n",
    "print(f\"How many nones in bandgap: {len(df_all_identified)-len(df_check)}\")\n",
    "df_all_identified['bandgap'] = df_all_identified['bandgap'].fillna(0)\n",
    "df_all_identified['bandgap'] = df_all_identified['bandgap']*6.24150974e18\n",
    "\n",
    "df_all_identified['etl_key'] = df_all_identified['etl'].apply(lambda x: ';'.join(x))\n",
    "df_all_identified['htl_key'] = df_all_identified['htl'].apply(lambda x: ';'.join(x))\n",
    "df_all_identified['bandgap_key'] = df_all_identified['bandgap'].round(decimals=4)\n",
    "\n",
    "df_all_identified = df_all_identified.groupby(['reduced_formulas', 'etl_key', 'htl_key', 'bandgap_key']).agg({\n",
    "                       'reduced_formulas': 'first',\n",
    "                       'etl': 'first',\n",
    "                       'htl': 'first',\n",
    "                       'bandgap': 'mean',\n",
    "                       'device_stack': 'first',\n",
    "                       'pce': 'mean',\n",
    "                      }).reset_index(drop=True)\n",
    "\n",
    "df_all_identified"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c15cee1b-f66a-4f74-a5a9-bc149f170931",
   "metadata": {},
   "source": [
    "# Prepare SMILES dictionary\n",
    "\n",
    "The following code does:\n",
    "- transform the CID dictionary into SMILES dictionary (or load if SMILES dictionary already exists)\n",
    "- Add the SMILES from the dictionary\n",
    "- removes all rows where ETLs or HTLs are not completely identfied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "20c66d24-15ba-4562-9212-50fea23fbab5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length before filtering: 5449\n",
      "Length after filtering out elements where etl or htl smiles is None: 5449\n",
      "The two above numbers should be the same. Otherwise something in the name to SMILES conversion did not work.\n"
     ]
    }
   ],
   "source": [
    "# Transform the dictionary entries to SMILES\n",
    "\n",
    "try:\n",
    "    with open('data_RO2/SMILES_dictionary.pkl', 'rb') as f:\n",
    "        SMILES_dict = pickle.load(f)\n",
    "except:\n",
    "    with open('data_RO2/dict_all_cells_v2.pkl', 'rb') as f:\n",
    "        CID_dict = pickle.load(f)\n",
    "    \n",
    "    def CID_to_SMILES(CID):\n",
    "        '''\n",
    "        This searches for a CTL material's CID in PubChem.\n",
    "        Argument: industry_name (str) - the name of the material\n",
    "        Value: CID (int) - the CID of the material\n",
    "        '''\n",
    "        url = f\"https://pubchem.ncbi.nlm.nih.gov/rest/pug/compound/cid/{CID}/property/CanonicalSMILES/JSON\"\n",
    "        \n",
    "        response = requests.get(url)\n",
    "    \n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            data = data['PropertyTable']['Properties'][0]['CanonicalSMILES']\n",
    "            return data\n",
    "        else:\n",
    "            print('debug: SMILES could not be retrieved')\n",
    "            raise Exception(f\"Error: Could not retrieve SMILES from this CID. Status code: {response.status_code}\")\n",
    "            return None\n",
    "    \n",
    "    #initialize new dictionary where the SMILES will be written\n",
    "    SMILES_dict = {}\n",
    "    \n",
    "    # populate the SMILES dictionary\n",
    "    for index, name in enumerate(CID_dict):\n",
    "        print(f\"{index+1}/{len(CID_dict)}. Next up: {name}\")\n",
    "        CID = CID_dict[name]\n",
    "        if CID is not None:\n",
    "            SMILES = CID_to_SMILES(CID)\n",
    "            SMILES_dict[name] = SMILES\n",
    "        else:\n",
    "            SMILES_dict[name] = None\n",
    "    \n",
    "    with open('data_RO2/SMILES_dictionary.pkl', 'wb') as f:\n",
    "        pickle.dump(SMILES_dict, f)\n",
    "\n",
    "\n",
    "# Write SMILES into the dataframe\n",
    "df_all_identified['pce'] = df_all_identified['pce'].astype(float)\n",
    "\n",
    "# the SMILES_dict contains no entry for \"no ctl\" yet\n",
    "SMILES_dict['none'] = \"no_ctl\"\n",
    "\n",
    "for index, row in df_all_identified.iterrows():\n",
    "    etl_SMILES = []\n",
    "    for element in row['etl']:\n",
    "        etl_SMILES.append(SMILES_dict[element])\n",
    "    df_all_identified.loc[index, 'etl_SMILES'] = str(etl_SMILES)\n",
    "    htl_SMILES = []\n",
    "    for element in row['htl']:\n",
    "        htl_SMILES.append(SMILES_dict[element])\n",
    "    df_all_identified.loc[index, 'htl_SMILES'] = str(htl_SMILES)\n",
    "\n",
    "# output of the function are strings, so we transform to lists\n",
    "df_all_identified['etl_SMILES'] = df_all_identified['etl_SMILES'].apply(ast.literal_eval)\n",
    "df_all_identified['htl_SMILES'] = df_all_identified['htl_SMILES'].apply(ast.literal_eval)\n",
    "\n",
    "# drop rows where the etl_SMILES or the htl_SMILES contain None\n",
    "def has_all_non_none_elements(data_list):\n",
    "    \"\"\"Checks if all elements in a list are not None.\"\"\"\n",
    "    return all(element is not None for element in data_list)\n",
    "\n",
    "# Check: Filter rows where any element in etl_SMILES or htl_SMILES is None\n",
    "print(f\"Length before filtering: {len(df_all_identified)}\")\n",
    "df_all_identified = df_all_identified[df_all_identified['etl_SMILES'].apply(has_all_non_none_elements) &\n",
    "                                 df_all_identified['htl_SMILES'].apply(has_all_non_none_elements)]\n",
    "print(f\"Length after filtering out elements where etl or htl smiles is None: {len(df_all_identified)}\")\n",
    "print(f\"The two above numbers should be the same. Otherwise something in the name to SMILES conversion did not work.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd178d5-8e29-4c0f-b23c-fe95d4fd3348",
   "metadata": {},
   "source": [
    "# Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5d7e3250-885c-496a-84c8-266cc9dd044c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df_all_identified.to_csv('data_RO2/df_ml_ready.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
