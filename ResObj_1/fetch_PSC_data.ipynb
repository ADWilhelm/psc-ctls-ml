{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching data from NOMAD\n",
    "\n",
    "This file is used to collect the perovskite solar cell data for all 43 119 cells from the NOMAD repository. It collects each entry's PCE, ETL, HTL and publication reference. If necessary, more properties can be accessed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fetching data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to extract values from the downloaded entries\n",
    "def extract_values(entry):\n",
    "    try:\n",
    "        htl.append(entry['results']['properties']['optoelectronic']['solar_cell']['hole_transport_layer'])\n",
    "    except:\n",
    "        htl.append('None')\n",
    "    try:\n",
    "        etl.append(entry['results']['properties']['optoelectronic']['solar_cell']['electron_transport_layer'])\n",
    "    except:\n",
    "        etl.append('None')\n",
    "    try:\n",
    "        ref.append(entry['references'])\n",
    "    except:\n",
    "        ref.append('None')\n",
    "    return htl, etl, ref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gets all ~43 119 PSCs from NOMAD\n",
    "\n",
    "# initialize empty lists where collected values will be stored\n",
    "htl = []\n",
    "etl = []\n",
    "ref = []\n",
    "\n",
    "page_after_value = None\n",
    "base_url = 'https://nomad-lab.eu/prod/v1/api/v1/'\n",
    "\n",
    "# access NOMAD API and query for all cells with the property SolarCell that \n",
    "# have information in the mentioned sections:\n",
    "while True:\n",
    "    data = requests.post(f'{base_url}entries/query', json={\n",
    "        \"owner\": \"visible\",\n",
    "        \"aggregations\": {},\n",
    "        \"query\": {\n",
    "            \"and\": [\n",
    "                {\"sections:all\": [\"nomad.datamodel.results.SolarCell\"]},\n",
    "                ]},\n",
    "        \"required\": {\n",
    "            \"results\":{\n",
    "                \"material\": {\n",
    "                    \"chemical_formula_reduced\":\"*\",\n",
    "                    \"structural_type\":\"*\"},\n",
    "                \"properties\": {\n",
    "                   \"optoelectronic\":{\n",
    "                      \"band_gap\":\"*\",\n",
    "                      \"solar_cell\":{\n",
    "                          \"open_circuit_voltage\":\"*\",\n",
    "                          \"short_circuit_current_density\":\"*\",\n",
    "                          \"fill_factor\":\"*\",\n",
    "                          \"efficiency\":\"*\",\n",
    "                          }}},},\n",
    "        },\n",
    "        \"pagination\": {\"page_size\": 10,\n",
    "                       \"page_after_value\": page_after_value}\n",
    "        }).json()\n",
    "\n",
    "    if not data['data']:\n",
    "        print('debug: no data found')\n",
    "        break\n",
    "\n",
    "    # instructions for the last page\n",
    "    if 'next_page_after_value' not in data['pagination'].keys():\n",
    "        for entry in data['data']:\n",
    "            if 'results' not in entry.keys():\n",
    "                continue\n",
    "            elif 'chemical_formula_reduced' not in entry['results']['material'].keys():\n",
    "                continue\n",
    "            else:\n",
    "                extract_values(entry)\n",
    "        break\n",
    "\n",
    "    page_after_value = data['pagination']['next_page_after_value']\n",
    "\n",
    "    # extract the values from current page\n",
    "    for entry in data['data']:\n",
    "        if 'results' not in entry.keys():\n",
    "            continue\n",
    "        else:\n",
    "            extract_values(entry)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put result of query into a pandas dataframe\n",
    "df_all_ctls = pd.DataFrame({'etl': etl, 'htl': htl, 'ref': ref})\n",
    "\n",
    "# clean up ref so it shows only the reference to the paper\n",
    "df_all_ctls['ref'] = df_all_ctls['ref'].apply(lambda x: x[0] if x else None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pickle the result\n",
    "Fetching all those entries took ca. 30 mins, so I pickle them here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data_RO1/df_all_ctls.pkl', 'wb') as f:\n",
    "    pickle.dump(df_all_ctls, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
