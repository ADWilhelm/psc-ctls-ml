{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "47238d35-3a4d-48fd-b874-ca542102c835",
   "metadata": {},
   "source": [
    "# GNN_1\n",
    "\n",
    "In 1000 epochs to 13.32 validation loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0e80bd69-698f-4b04-a57e-1c3a03dadbdc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "########### insert into GNN definition section ####################\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import MessagePassing, global_mean_pool, MLP, global_add_pool\n",
    "from torch_geometric.nn import GCNConv\n",
    "\n",
    "class Net(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "\n",
    "        self.etl_embedding_dimensions = 16\n",
    "        self.htl_embedding_dimensions = 16\n",
    "        self.absorber_dimensions = 76\n",
    "        self.bandgap_dimension = 1\n",
    "        self.hidden_dimension = 32\n",
    "        self.number_of_regression_layers = 3\n",
    "\n",
    "        self.etl_mpnn = GCNConv(in_channels=1, out_channels=self.etl_embedding_dimensions)\n",
    "        self.htl_mpnn = GCNConv(in_channels=1, out_channels=self.htl_embedding_dimensions)\n",
    "\n",
    "        self.fc1 = torch.nn.Linear(self.etl_embedding_dimensions + self.htl_embedding_dimensions + self.absorber_dimensions + self.bandgap_dimension, self.hidden_dimension)\n",
    "        \n",
    "        self.regression_layers = torch.nn.ModuleList([self.fc1])\n",
    "        self.regression_layers.extend([torch.nn.Linear(self.hidden_dimension,  self.hidden_dimension) for i in range(1, self.number_of_regression_layers-1)])\n",
    "\n",
    "        self.fc_out = torch.nn.Linear(self.hidden_dimension, 1)\n",
    "\n",
    "    def forward(self, etl_features, htl_features, etl_edge_indices, htl_edge_indices, absorbers, bandgap):\n",
    "        etl_x = self.etl_mpnn(etl_features, etl_edge_indices)\n",
    "        etl_x = global_mean_pool(etl_x, torch.zeros(etl_x.size(0), dtype=torch.long))\n",
    "        \n",
    "        htl_x = self.htl_mpnn(htl_features, htl_edge_indices)\n",
    "        htl_x = global_mean_pool(htl_x, torch.zeros(htl_x.size(0), dtype=torch.long))\n",
    "        \n",
    "        x = torch.cat([etl_x, htl_x, absorbers, bandgap], dim=1)\n",
    "        for layer in self.regression_layers: \n",
    "            x = F.leaky_relu(layer(x))\n",
    "        \n",
    "        x = self.fc_out(x)\n",
    "        x = F.softplus(x)\n",
    "        return x\n",
    "\n",
    "####### end of insert #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8de36a2a-61a9-49bf-af7c-03df90c0db63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'AveragedModel' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m######### insert into Training section ##############\u001b[39;00m\n\u001b[1;32m      3\u001b[0m decay \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.995\u001b[39m\n\u001b[0;32m----> 4\u001b[0m averaged_model \u001b[38;5;241m=\u001b[39m \u001b[43mAveragedModel\u001b[49m(model, multi_avg_fn\u001b[38;5;241m=\u001b[39mget_ema_multi_avg_fn(decay))\n\u001b[1;32m      6\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mAdam(model\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-3\u001b[39m, weight_decay\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1e-4\u001b[39m)\n\u001b[1;32m      7\u001b[0m criterion \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mMSELoss()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'AveragedModel' is not defined"
     ]
    }
   ],
   "source": [
    "######### insert into Training section ##############\n",
    "\n",
    "decay = 0.995\n",
    "averaged_model = AveragedModel(model, multi_avg_fn=get_ema_multi_avg_fn(decay))\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)\n",
    "criterion = torch.nn.MSELoss()\n",
    "\n",
    "num_epochs = 1000\n",
    "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, steps_per_epoch=len(train_loader), epochs=num_epochs, pct_start=0.1,final_div_factor=1e2)\n",
    "\n",
    "######### end of insert ################"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef50ba8-6df3-4465-8f73-64b1b0f4e947",
   "metadata": {},
   "source": [
    "# GNN_2\n",
    "Everything the same as above, but for the embedding dimensions being 32 instead of 16.\n",
    "Overfits a lot."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2743263e-0570-4bf8-b2b1-bf9b6574a3ff",
   "metadata": {},
   "source": [
    "# GNN_3\n",
    "\n",
    "Went back to config of GNN_1, but added another input feature, atomweight."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf971bbf-c266-42a4-bbed-421c5c36be00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in smiles_to_graph insert:\n",
    "    atom_features = []\n",
    "    for atom in mol.GetAtoms():\n",
    "        atomic_num = atom.GetAtomicNum()\n",
    "        atomic_weight = atom.GetMass()\n",
    "        atom_features.append([atomic_num, atomic_weight])\n",
    "    x = torch.tensor(atom_features, dtype=torch.float)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76c5c385-2218-46ea-8b48-c3b1aeb064ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for the default data in creating MolecularDataset class, change dimensions of the zero verctor:\n",
    "default_data = {'x': torch.zeros((1,2),  dtype=torch.float), 'edge_index': torch.zeros((2,1), dtype=torch.long)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea793212-96c1-48c5-b289-0c7baddba1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in the net definitions, change input channels to 2\n",
    "        self.etl_mpnn = GCNConv(in_channels=2, out_channels=self.etl_embedding_dimensions)\n",
    "        self.htl_mpnn = GCNConv(in_channels=2, out_channels=self.htl_embedding_dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b78298e-1c12-4488-b24f-e0a1c508ea29",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f650a072-04b5-4446-9e69-ce25d9b3aadd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (etl_mpnn): GCNConv(1, 16)\n",
       "  (htl_mpnn): GCNConv(1, 16)\n",
       "  (fc1): Linear(in_features=109, out_features=32, bias=True)\n",
       "  (regression_layers): ModuleList(\n",
       "    (0): Linear(in_features=109, out_features=32, bias=True)\n",
       "    (1): Linear(in_features=32, out_features=32, bias=True)\n",
       "  )\n",
       "  (fc_out): Linear(in_features=32, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Net()\n",
    "model.load_state_dict(torch.load('models/GNN_1_best.pth'))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26613898-4767-4119-a5bf-751cc97bd92d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'eval_loader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Evaluate the model\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():  \u001b[38;5;66;03m# Disable gradient calculation for evaluation\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m batch \u001b[38;5;129;01min\u001b[39;00m \u001b[43meval_loader\u001b[49m:\n\u001b[1;32m      7\u001b[0m         etl_features \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124metl_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m      8\u001b[0m         htl_features \u001b[38;5;241m=\u001b[39m batch[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhtl_features\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msqueeze(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'eval_loader' is not defined"
     ]
    }
   ],
   "source": [
    "all_predictions = []\n",
    "all_labels = []\n",
    "\n",
    "# Evaluate the model\n",
    "with torch.no_grad():  # Disable gradient calculation for evaluation\n",
    "    for batch in eval_loader:\n",
    "        etl_features = batch['etl_features'].squeeze(0)\n",
    "        htl_features = batch['htl_features'].squeeze(0)\n",
    "        etl_edge_indices = batch['etl_edge_indices'].squeeze(0)\n",
    "        htl_edge_indices = batch['htl_edge_indices'].squeeze(0)\n",
    "        absorber = batch['absorber']\n",
    "        bandgap = batch['bandgap']\n",
    "        true_labels = batch['pce']\n",
    "        \n",
    "        # Forward pass\n",
    "        predictions = model(etl_features, htl_features, etl_edge_indices, htl_edge_indices, absorber, bandgap)\n",
    "        \n",
    "        # Store predictions and true labels\n",
    "        all_predictions.extend(predictions.cpu().numpy())\n",
    "        all_labels.extend(true_labels.cpu().numpy())\n",
    "\n",
    "# Compute evaluation metrics (e.g., Mean Squared Error)\n",
    "mse = mean_squared_error(all_labels, all_predictions)\n",
    "print(f\"Mean Squared Error: {mse}\")\n",
    "\n",
    "# You can also compute other metrics like R^2 score, MAE, etc.\n",
    "from sklearn.metrics import r2_score, mean_absolute_error\n",
    "\n",
    "r2 = r2_score(all_labels, all_predictions)\n",
    "mae = mean_absolute_error(all_labels, all_predictions)\n",
    "\n",
    "print(f\"R^2 Score: {r2}\")\n",
    "print(f\"Mean Absolute Error: {mae}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f040e9-f1fa-483f-8726-67ec5d8deefa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
